{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7638fdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "# The datasets module in sklearn (Scikit-learn) provides utilities to load datasets, \n",
    "# including methods to load and fetch popular reference datasets. \n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "# the metrics module provides a comprehensive set of tools to evaluate and \n",
    "# measure the performance, similarity, and distance of machine learning models and data points.\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fc8d910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "cancer = datasets.load_breast_cancer()\n",
    "print(cancer.feature_names)\n",
    "print(cancer.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82eba0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cancer.data\n",
    "y = cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f09af148",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ef64b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.029e+00 1.733e+01 5.879e+01 ... 1.750e-01 4.228e-01 1.175e-01]\n",
      " [2.109e+01 2.657e+01 1.427e+02 ... 2.903e-01 4.098e-01 1.284e-01]\n",
      " [9.173e+00 1.386e+01 5.920e+01 ... 5.087e-02 3.282e-01 8.490e-02]\n",
      " ...\n",
      " [1.429e+01 1.682e+01 9.030e+01 ... 3.333e-02 2.458e-01 6.120e-02]\n",
      " [1.398e+01 1.962e+01 9.112e+01 ... 1.827e-01 3.179e-01 1.055e-01]\n",
      " [1.218e+01 2.052e+01 7.722e+01 ... 7.431e-02 2.694e-01 6.878e-02]] [1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 0 1 0\n",
      " 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1\n",
      " 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1\n",
      " 1 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 1 0 1 1 1 0 1 0 1 0 1 0\n",
      " 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0 1\n",
      " 0 0 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 0 1 1 1 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 0\n",
      " 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 1 0\n",
      " 0 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1\n",
      " 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0 0 1 0 0 1 1 0 1 0 1 1 0\n",
      " 1 1 0 0 0 1 1 1 0 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 0 0 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0\n",
      " 1 0 0 1 0 1 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f01b0a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# later when we want to print out the actual result we can index 1 and 0 to these classes\n",
    "classes = ['malignant' 'benign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d2d09c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSVM - support vector machines\\ncreates a hyperplane (the same distance to a pair of points of the different classes)\\nso we can have infinite number of hyperplanes\\nHow to pick the best one? Find the two cloest points to the line that are furthest possible away aka. we want to maximize margin\\nWhat if dots are meshed up? We use Kernels - a function takes in features to a higher dimension, and data are not meshed together\\nkernels don't always work, and we would repeat the process \\nSoft margin vs hard margin\\nSoft margin - allow for a few points to exist in between, in order to get a better classifier\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "SVM - support vector machines\n",
    "creates a hyperplane (the same distance to a pair of points of the different classes)\n",
    "so we can have infinite number of hyperplanes\n",
    "How to pick the best one? Find the two cloest points to the line that are furthest possible away aka. we want to maximize margin\n",
    "What if dots are meshed up? We use Kernels - a function takes in features to a higher dimension, and data are not meshed together\n",
    "kernels don't always work, and we would repeat the process \n",
    "Soft margin vs hard margin\n",
    "Soft margin - allow for a few points to exist in between, in order to get a better classifier\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c290712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "clf1 = svm.SVC()\n",
    "clf1.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf1.predict(x_test)\n",
    "\n",
    "acc = metrics.accuracy_score(y_test, y_pred) #the oder doesn't even matter becuase we are just comparing two lists\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32a51289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "clf2 = svm.SVC(kernel = \"linear\")\n",
    "clf2.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf2.predict(x_test)\n",
    "\n",
    "acc = metrics.accuracy_score(y_test, y_pred) #the oder doesn't even matter becuase we are just comparing two lists\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31ed724e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "clf3 = svm.SVC(kernel = \"linear\", C=2) #c --> soft margin, how many points are allowed in the margin\n",
    "clf3.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf3.predict(x_test)\n",
    "\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4c235cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# Compare the K nearest neighbour classifier \n",
    "clf4 = KNeighborsClassifier(n_neighbors = 13)\n",
    "clf4.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf4.predict(x_test)\n",
    "\n",
    "acc = metrics.accuracy_score(y_test, y_pred) \n",
    "print(acc)\n",
    "\n",
    "# it is entirely possible to get the same accuracy for different values of n_neighbors in the KNeighborsClassifier\n",
    "# Eg.in a binary classification problem, 5 out of 7 neighbors vote for class 1 and the other 2 for class 0, \n",
    "# then increasing the neighbors to 9 might still result in a majority vote for class 1 even if the new neighbors vote differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "703fdee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usually KNN does not woek as well as SVM for datasets with a lot of features (here there are 30). \n",
    "# But the result is surprising here, that's why we need to test out different machine learning algo\n",
    "\n",
    "# while they might produce the same accuracy, the underlying decision process is different:\n",
    "\n",
    "# SVM tries to maximize the margin between the two classes.\n",
    "# KNN bases its decision on the proximity of data points."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
